{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "import joblib\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from src.data import getAbsolute, resampling, explore_dataset as ex\n",
    "from src.features import kpw_build_features, standardization\n",
    "from src.models import cross_validation, save_predictions, blending\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "\n",
    "Understand the training set and test set, and what issues there are to determine what data preparation steps are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dataframe info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 22 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id_old       8000 non-null   int64  \n",
      " 1   Id           8000 non-null   int64  \n",
      " 2   GP           8000 non-null   int64  \n",
      " 3   MIN          8000 non-null   float64\n",
      " 4   PTS          8000 non-null   float64\n",
      " 5   FGM          8000 non-null   float64\n",
      " 6   FGA          8000 non-null   float64\n",
      " 7   FG%          8000 non-null   float64\n",
      " 8   3P Made      8000 non-null   float64\n",
      " 9   3PA          8000 non-null   float64\n",
      " 10  3P%          8000 non-null   float64\n",
      " 11  FTM          8000 non-null   float64\n",
      " 12  FTA          8000 non-null   float64\n",
      " 13  FT%          8000 non-null   float64\n",
      " 14  OREB         8000 non-null   float64\n",
      " 15  DREB         8000 non-null   float64\n",
      " 16  REB          8000 non-null   float64\n",
      " 17  AST          8000 non-null   float64\n",
      " 18  STL          8000 non-null   float64\n",
      " 19  BLK          8000 non-null   float64\n",
      " 20  TOV          8000 non-null   float64\n",
      " 21  TARGET_5Yrs  8000 non-null   int64  \n",
      "dtypes: float64(18), int64(4)\n",
      "memory usage: 1.3 MB\n",
      "None\n",
      "=== dataframe shape ===\n",
      "(8000, 22)\n",
      "=== Target Value Count ===\n",
      "1    6669\n",
      "0    1331\n",
      "Name: TARGET_5Yrs, dtype: int64\n",
      "=== dataframe describe ===\n",
      "             Id_old           Id           GP          MIN          PTS  \\\n",
      "count   8000.000000   8000.00000  8000.000000  8000.000000  8000.000000   \n",
      "mean    6856.971000   7798.50000    62.777875    18.576662     7.267088   \n",
      "std     3977.447579   2309.54541    17.118774     8.935263     4.318732   \n",
      "min        4.000000   3799.00000    -8.000000     2.900000     0.800000   \n",
      "25%     3413.750000   5798.75000    51.000000    12.000000     4.100000   \n",
      "50%     6787.500000   7798.50000    63.000000    16.800000     6.300000   \n",
      "75%    10299.250000   9798.25000    74.000000    23.500000     9.500000   \n",
      "max    13798.000000  11798.00000   123.000000    73.800000    34.200000   \n",
      "\n",
      "               FGM          FGA          FG%      3P Made          3PA  \\\n",
      "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
      "mean      2.807037     6.231212    44.608900     0.264525     0.816562   \n",
      "std       1.693373     3.584559     6.155453     0.384093     1.060964   \n",
      "min       0.300000     0.800000    21.300000    -1.100000    -3.100000   \n",
      "25%       1.600000     3.600000    40.400000     0.000000     0.100000   \n",
      "50%       2.400000     5.400000    44.400000     0.300000     0.800000   \n",
      "75%       3.700000     8.100000    48.700000     0.500000     1.500000   \n",
      "max      13.100000    28.900000    67.200000     1.700000     4.700000   \n",
      "\n",
      "               3P%          FTM          FTA          FT%         OREB  \\\n",
      "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
      "mean     19.583700     1.392525     1.947788    71.365825     1.077838   \n",
      "std      16.003155     0.926153     1.252352    10.430447     0.785670   \n",
      "min     -38.500000     0.000000     0.000000   -13.300000     0.000000   \n",
      "25%       8.400000     0.700000     1.000000    65.000000     0.500000   \n",
      "50%      19.500000     1.200000     1.700000    71.400000     0.900000   \n",
      "75%      30.600000     1.900000     2.600000    77.500000     1.500000   \n",
      "max      82.100000     8.100000    11.100000   168.900000     5.500000   \n",
      "\n",
      "              DREB          REB          AST          STL          BLK  \\\n",
      "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
      "mean      2.168500     3.245300     1.624513     0.648687     0.245212   \n",
      "std       1.392224     2.085154     1.355986     0.407626     0.821037   \n",
      "min       0.200000     0.300000     0.000000     0.000000   -17.900000   \n",
      "25%       1.100000     1.700000     0.700000     0.300000     0.100000   \n",
      "50%       1.900000     2.800000     1.300000     0.600000     0.200000   \n",
      "75%       2.900000     4.300000     2.200000     0.900000     0.400000   \n",
      "max      11.000000    15.900000    12.800000     3.600000    18.900000   \n",
      "\n",
      "               TOV  TARGET_5Yrs  \n",
      "count  8000.000000  8000.000000  \n",
      "mean      1.257763     0.833625  \n",
      "std       0.723270     0.372440  \n",
      "min       0.100000     0.000000  \n",
      "25%       0.700000     1.000000  \n",
      "50%       1.100000     1.000000  \n",
      "75%       1.600000     1.000000  \n",
      "max       5.300000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "ex.explore(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dataframe info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3799 entries, 0 to 3798\n",
      "Data columns (total 21 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Id_old   3799 non-null   int64  \n",
      " 1   Id       3799 non-null   int64  \n",
      " 2   GP       3799 non-null   int64  \n",
      " 3   MIN      3799 non-null   float64\n",
      " 4   PTS      3799 non-null   float64\n",
      " 5   FGM      3799 non-null   float64\n",
      " 6   FGA      3799 non-null   float64\n",
      " 7   FG%      3799 non-null   float64\n",
      " 8   3P Made  3799 non-null   float64\n",
      " 9   3PA      3799 non-null   float64\n",
      " 10  3P%      3799 non-null   float64\n",
      " 11  FTM      3799 non-null   float64\n",
      " 12  FTA      3799 non-null   float64\n",
      " 13  FT%      3799 non-null   float64\n",
      " 14  OREB     3799 non-null   float64\n",
      " 15  DREB     3799 non-null   float64\n",
      " 16  REB      3799 non-null   float64\n",
      " 17  AST      3799 non-null   float64\n",
      " 18  STL      3799 non-null   float64\n",
      " 19  BLK      3799 non-null   float64\n",
      " 20  TOV      3799 non-null   float64\n",
      "dtypes: float64(18), int64(3)\n",
      "memory usage: 623.4 KB\n",
      "None\n",
      "=== dataframe shape ===\n",
      "(3799, 21)\n",
      "=== dataframe describe ===\n",
      "             Id_old           Id           GP          MIN          PTS  \\\n",
      "count   3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean    7010.614109  1899.000000    62.853909    18.650224     7.328034   \n",
      "std     3954.173641  1096.821164    17.151740     8.727259     4.294724   \n",
      "min        1.000000     0.000000     6.000000     3.700000     0.700000   \n",
      "25%     3644.000000   949.500000    51.000000    12.200000     4.200000   \n",
      "50%     7062.000000  1899.000000    63.000000    17.000000     6.400000   \n",
      "75%    10402.500000  2848.500000    74.000000    23.300000     9.400000   \n",
      "max    13792.000000  3798.000000   126.000000    68.000000    33.000000   \n",
      "\n",
      "               FGM          FGA          FG%      3P Made          3PA  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean      2.835404     6.302580    44.599079     0.255962     0.796920   \n",
      "std       1.688427     3.579221     6.040168     0.380987     1.052862   \n",
      "min       0.300000     0.800000    25.100000    -1.000000    -2.700000   \n",
      "25%       1.600000     3.700000    40.500000     0.000000     0.100000   \n",
      "50%       2.500000     5.500000    44.600000     0.300000     0.800000   \n",
      "75%       3.700000     8.100000    48.500000     0.500000     1.500000   \n",
      "max      13.400000    26.200000    74.600000     1.600000     4.300000   \n",
      "\n",
      "               3P%          FTM          FTA          FT%         OREB  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean     19.234746     1.399842     1.953567    71.612924     1.096025   \n",
      "std      15.968989     0.926140     1.250376    10.457336     0.785678   \n",
      "min     -38.000000     0.000000     0.000000    23.700000     0.000000   \n",
      "25%       8.500000     0.700000     1.000000    65.000000     0.500000   \n",
      "50%      19.400000     1.200000     1.700000    71.500000     0.900000   \n",
      "75%      30.250000     1.900000     2.600000    78.000000     1.500000   \n",
      "max      73.800000     7.800000     9.800000   127.100000     6.900000   \n",
      "\n",
      "              DREB          REB          AST          STL          BLK  \\\n",
      "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
      "mean      2.179495     3.275783     1.636483     0.653593     0.257726   \n",
      "std       1.371935     2.070646     1.335496     0.410573     0.639660   \n",
      "min       0.200000     0.300000     0.000000     0.000000    -7.100000   \n",
      "25%       1.200000     1.800000     0.600000     0.400000     0.100000   \n",
      "50%       1.900000     2.800000     1.300000     0.600000     0.200000   \n",
      "75%       2.900000     4.300000     2.300000     0.900000     0.400000   \n",
      "max      12.000000    18.500000     9.000000     2.700000    14.800000   \n",
      "\n",
      "               TOV  \n",
      "count  3799.000000  \n",
      "mean      1.257910  \n",
      "std       0.712449  \n",
      "min       0.100000  \n",
      "25%       0.700000  \n",
      "50%       1.100000  \n",
      "75%       1.600000  \n",
      "max       5.200000  \n"
     ]
    }
   ],
   "source": [
    "ex.explore(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Concerns\n",
    "- GP, 3PM, 3PA, 3p%, FT%, BLK have negative value as minimum - **Convert to absolute value** \n",
    "- There are potential outliers in the value between 75% mark and MAX is huge jump across all features\n",
    "- Check if all made value is smaller than attempt value\n",
    "- All % values are bit off and not close to Made/attempt - **Consider dropping these fields or recreate them**\n",
    "- BLK has outliers - **Fix it or drop these**\n",
    "- 3PA and FTA has 0 value - Need to ensure 3PM and FTM are also 0 in these cases\n",
    "- Imbalanced data - 21 : 4 Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Convert to absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_abs = getAbsolute.abs(pd.read_csv(\"../data/raw/train.csv\"),'train')\n",
    "df_test_abs = getAbsolute.abs(pd.read_csv(\"../data/raw/test.csv\"),'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- Recalculate percentage features\n",
    "- Add new features\n",
    "- Drop features based on coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = kpw_build_features.build(df_train_abs)\n",
    "df_test_clean = kpw_build_features.build(df_test_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_clean.pop('TARGET_5Yrs')\n",
    "X = df_train_clean.iloc[:,2:] \n",
    "X_test = df_test_clean.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X_test = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_val, y, y_val = train_test_split(X,y,test_size=0.2, random_state=8, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump all processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/X_test']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X, \"../data/processed/X\")\n",
    "joblib.dump(y, \"../data/processed/y\")\n",
    "joblib.dump(X_test, \"../data/processed/X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_roc_auc_score = 0.0\n",
    "def get_roc_auc_score(classifier):\n",
    "    global max_roc_auc_score\n",
    "    roc_score_training, roc_score_val = cross_validation.cv(classifier, X, y)\n",
    "    combined_roc_auc_score = roc_score_val * (1 - abs(roc_score_training - roc_score_val))\n",
    "    hot_icon = u\"\\U0001F525\"\n",
    "    cold_icon = u\"\\U00002744\"\n",
    "\n",
    "    if max_roc_auc_score < combined_roc_auc_score:\n",
    "        print(f\"{hot_icon} The score {str(combined_roc_auc_score)} is better than {str(max_roc_auc_score)} so save the model {hot_icon}\")\n",
    "        # joblib.dump(classifier, \"../models/kpw_best_classifier_assignmentA\")\n",
    "        max_roc_auc_score = combined_roc_auc_score\n",
    "    else:\n",
    "        print(f\"{cold_icon} The score {str(combined_roc_auc_score)} is not better {cold_icon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg ROC AUC score of training set is: 0.7041085862252553\n",
      "Avg ROC AUC score of valuation set is: 0.7009464471929986\n",
      "🔥 The score 0.6987299570728079 is better than 0.0 so save the model 🔥\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.3, C=0.01)\n",
    "get_roc_auc_score(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending approach\n",
    "Create a collection of classifier with different training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binned_clean = pd.DataFrame(X)\n",
    "df_binned_clean['TARGET_5Yrs'] = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_binned_clean[df_binned_clean[19]==3]\n",
    "y3 = df3.pop('TARGET_5Yrs')\n",
    "X3 = df3.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = np.asarray(X3)\n",
    "y3 = np.asarray(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRFClassifier(max_depth=3, learning_rate=0.1, objective='binary:logistic')\n",
    "model2 = xgb.XGBRFClassifier(max_depth=4, learning_rate=0.03, objective='binary:logistic', scale_pos_weight=0.4, subsample=0.6) \n",
    "model3 = xgb.XGBRFClassifier(max_depth=4, learning_rate=0.03, objective='binary:logistic', scale_pos_weight=0.2, subsample=0.3)\n",
    "model4 = xgb.XGBClassifier(max_depth=5, learning_rate=0.001, objective='binary:logistic')\n",
    "model5 = xgb.XGBClassifier(max_depth=4, learning_rate=0.03, objective='binary:logistic', scale_pos_weight=0.4, subsample=0.4)\n",
    "model6 = xgb.XGBRFClassifier(max_depth=4, learning_rate=0.03, objective='binary:logistic', scale_pos_weight=0.4, subsample=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:07:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:07:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:07:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:07:41] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:07:42] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:07:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model1 = model1.fit(X3,y3)\n",
    "model2 = model2.fit(X3,y3)\n",
    "model3 = model3.fit(X3,y3)\n",
    "model4 = model4.fit(X3,y3)\n",
    "model5 = model5.fit(X3,y3)\n",
    "model6 = model6.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model, save model and generate prediction in Blending approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Creating train, validation and test sets for blending.\n",
      "Blending.\n",
      "==== ROC AUC Score for training set ====\n",
      "0.78670987499505\n",
      "==== ROC AUC Score for valuation set ====\n",
      "0.6856181871470279\n",
      "Linear stretch of predictions to [0,1]\n",
      "Saving Results.\n"
     ]
    }
   ],
   "source": [
    "clfs = [ model1, model2, model3, model4, model5, model6]\n",
    "blending.blend(X,y,X_val,y_val,X_test,clfs,'../data/predictions/kpw_submission_assignmentB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Creating train, validation and test sets for blending.\n",
      "Blending.\n",
      "==== ROC AUC Score for training set ====\n",
      "0.75366351184269\n",
      "==== ROC AUC Score for valuation set ====\n",
      "0.6919604107720576\n",
      "Linear stretch of predictions to [0,1]\n",
      "Saving Results.\n"
     ]
    }
   ],
   "source": [
    "clfs = [ model3, model6]\n",
    "blending.blend(X,y,X_val,y_val,X_test,clfs,'../data/predictions/kpw_submission_assignmentB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
